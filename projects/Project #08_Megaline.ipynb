{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb13035",
   "metadata": {},
   "source": [
    "# Megaline\n",
    "\n",
    "### Description\n",
    "Mobile company Megaline is not happy to see that many of its customers are using legacy plans. They want to develop a model that can analyze customer behavior and recommend one of Megaline's new plans: Smart or Ultra.\n",
    "\n",
    "You have access to behavioral data for subscribers who have already switched to the new plans (from the Statistical Data Analysis course project). For this classification task you must create a model that chooses the correct plan. Since you have already done the step of processing the data, you can jump right into creating the model.\n",
    "\n",
    "Develop a model with the greatest possible accuracy. In this project, the accuracy threshold is 0.75. Use the dataset to check accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9517d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f3c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"datasets/users_behavior.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f367c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#df.info()\n",
    "\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15e2baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['mb_used'], axis=1)\n",
    "target = df['mb_used']\n",
    "\n",
    "# Segment the data into training and validation sets\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Split training set into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_train, target_train, test_size=0.33, random_state=12345)\n",
    "\n",
    "# Check the resulting sets\n",
    "print(\"Training set size:\", features_train.shape)\n",
    "print(\"Validation set size:\", features_valid.shape)\n",
    "print(\"Test set size:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c95a1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "#Hyperparameters\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeRegressor(max_depth=depth, random_state=12345) # initializes the model builder with the parameters random_state=12345 and max_depth=depth\n",
    "    model.fit(features_train, target_train) # Train the model\n",
    "    predictions_valid = model.predict(features_valid) # Get the predictions\n",
    "    result = mean_squared_error(target_valid, predictions_valid)**0.5 # Evaluate the model\n",
    "\n",
    "\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "\n",
    "print(f\"RECM = {best_result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b68eb",
   "metadata": {},
   "source": [
    "# Investigate the quality of different models by changing the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e995ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "for depth in range(3, 8):\n",
    "    model = DecisionTreeRegressor(max_depth=depth, random_state=12345) # initializes the model builder with the parameters random_state=12345 and max_depth=depth\n",
    "    model.fit(features_train, target_train) # Train the model\n",
    "    predictions_valid = model.predict(features_valid) # Get the predictions\n",
    "    result = mean_squared_error(target_valid, predictions_valid)**0.5 # Evaluate the model\n",
    "\n",
    "\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "\n",
    "print(f\"RECM = {best_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68e38e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "for depth in range(1, 9):\n",
    "    model = DecisionTreeRegressor(max_depth=depth, random_state=12345) # initializes the model builder with the parameters random_state=12345 and max_depth=depth\n",
    "    model.fit(features_train, target_train) # Entrenar el modelo\n",
    "    predictions_valid = model.predict(features_valid) # Get the predictions\n",
    "    result = mean_squared_error(target_valid, predictions_valid)**0.5 # Evaluate the model\n",
    "\n",
    "\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "\n",
    "print(f\"RECM = {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b969346",
   "metadata": {},
   "source": [
    "# It seems that changing the hyperparameters does not actually alter the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324cb48",
   "metadata": {},
   "source": [
    "# Additional task: do a sanity test on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecd4353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model = None\n",
    "worst_result = 0\n",
    "worst_depth = 0\n",
    "\n",
    "for depth in range(1, 10):\n",
    "    model = DecisionTreeRegressor(max_depth=depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "    \n",
    "    # Compare and save the worst model\n",
    "    if result > worst_result:\n",
    "        worst_model = model\n",
    "        worst_result = result\n",
    "        worst_depth = depth\n",
    "\n",
    "print(f\"Worst model = {worst_depth}): {worst_result}\")\n",
    "\n",
    "print(f\"Best model = {best_depth}): {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6836b",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "It seems that in this case, both the \"worst sanity model\" model performs as well as the \"best sanity model\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
